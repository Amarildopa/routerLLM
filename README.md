# üöÄ RouterLLM - Seu Roteador Inteligente

Um roteador de modelos LLM que escolhe automaticamente o melhor modelo para cada tarefa, otimizando **custo** e **performance**.

## ‚ú® Features

- üß† **Roteamento Inteligente**: Analisa sua pergunta e escolhe o modelo ideal
- üí∞ **Otimiza√ß√£o de Custo**: Usa modelos baratos para tarefas simples, premium para complexas
- ‚ö° **API REST**: Interface simples e r√°pida
- üìä **Dashboard Web**: Interface visual moderna com m√©tricas em tempo real
- üìà **M√©tricas Prometheus**: Monitoramento avan√ßado e alertas
- üîß **Configur√°vel**: F√°cil de ajustar regras e adicionar novos modelos
- üéØ **Teste Integrado**: Interface para testar a API diretamente no dashboard

## üéØ Como Funciona

O RouterLLM analisa sua mensagem e decide qual modelo usar:

- **Perguntas simples** ‚Üí `GPT-4o Mini` (r√°pido e barato)
- **C√≥digo/Debug** ‚Üí `GPT-4` (precis√£o m√°xima)
- **Textos longos** ‚Üí `Claude 3.5 Sonnet` (contexto gigante)
- **Conte√∫do criativo** ‚Üí `Gemini 1.5 Pro` (fluidez e criatividade)
- **Caso geral** ‚Üí `Claude 3 Haiku` (balanceado)

## üöÄ Instala√ß√£o

### Desenvolvimento Local
```bash
# Clone o projeto
git clone <seu-repo>
cd router_llm

# Instale depend√™ncias
pip install -r requirements.txt

# Configure as chaves de API
cp config.env.example .env
# Edite o arquivo .env com suas chaves

# Execute
python main.py
```

### Docker (Recomendado)
```bash
# Clone o projeto
git clone <seu-repo>
cd router_llm

# Configure as chaves de API
cp config.env.example .env
# Edite o arquivo .env com suas chaves

# Deploy autom√°tico
./deploy.sh dev

# Ou manualmente
docker-compose up -d
```

### Deploy em Produ√ß√£o
```bash
# Deploy em produ√ß√£o
./deploy.sh prod

# Ou usando docker-compose
docker-compose -f docker-compose.prod.yml up -d
```

## üì° Uso da API

### Chat B√°sico
```bash
curl -X POST "http://localhost:8000/chat" \
  -H "Content-Type: application/json" \
  -d '{"message": "Como fazer um loop em Python?"}'
```

### For√ßar Modelo Espec√≠fico
```bash
curl -X POST "http://localhost:8000/chat" \
  -H "Content-Type: application/json" \
  -d '{"message": "Ol√°!", "force_model": "gpt-4o-mini"}'
```

### Ver Estat√≠sticas
```bash
curl "http://localhost:8000/stats"
```

### Home Page (Chat)
```bash
# P√°gina inicial com chat integrado
http://localhost:8000/
```

### Dashboard Web
```bash
# Dashboard com m√©tricas e configura√ß√µes
http://localhost:8000/dashboard
```

### Configura√ß√£o de APIs
```bash
# Tela para configurar chaves de API
http://localhost:8000/api-config
```

### M√©tricas Prometheus
```bash
curl "http://localhost:8000/metrics"
```

## ‚öôÔ∏è Configura√ß√£o

Edite `config.py` para:
- Adicionar novos modelos
- Ajustar custos
- Modificar regras de roteamento
- Configurar APIs dos provedores

## üöÄ Deploy em Produ√ß√£o

### Op√ß√µes de Deploy

1. **Docker (Local/VPS)**
   ```bash
   ./deploy.sh prod
   ```

2. **Vercel (Serverless)**
   ```bash
   # Instale Vercel CLI
   npm i -g vercel
   
   # Configure as vari√°veis de ambiente
   vercel env add OPENAI_API_KEY
   vercel env add ANTHROPIC_API_KEY
   vercel env add GOOGLE_API_KEY
   
   # Deploy
   vercel --prod
   ```

3. **Railway/Render/Heroku**
   - Use o `Dockerfile` fornecido
   - Configure as vari√°veis de ambiente
   - Deploy autom√°tico

### Monitoramento
- Logs: `docker-compose logs -f`
- Health check: `curl http://localhost:8000/`
- M√©tricas: `curl http://localhost:8000/stats`

## üîß Pr√≥ximos Passos

1. ‚úÖ **APIs reais implementadas** (OpenAI, Anthropic, Google)
2. **Adicionar autentica√ß√£o**
3. **Implementar cache Redis**
4. **Dashboard web**
5. **M√©tricas avan√ßadas com Prometheus**

---

**Feito com ‚ù§Ô∏è para otimizar seus custos com LLMs!**
