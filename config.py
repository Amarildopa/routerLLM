#!/usr/bin/env python3
"""
‚öôÔ∏è Configura√ß√µes do RouterLLM
Aqui voc√™ define modelos, custos e regras
"""

import os
from typing import Dict, List, Optional

class RouterConfig:
    def __init__(self):
        # üîë Detectar APIs dispon√≠veis baseado nas chaves configuradas
        self.available_providers = self._detect_available_providers()
        # ü§ñ Modelos dispon√≠veis e suas caracter√≠sticas
        self.models = {
            "gpt-4o-mini": {
                "provider": "openai",
                "cost_per_1k_tokens": 0.00015,
                "max_tokens": 16000,
                "speed": "fast",
                "quality": "good",
                "use_case": "Perguntas simples, respostas r√°pidas"
            },
            "gpt-4": {
                "provider": "openai", 
                "cost_per_1k_tokens": 0.03,
                "max_tokens": 8000,
                "speed": "medium",
                "quality": "excellent",
                "use_case": "C√≥digo, racioc√≠nio complexo, precis√£o"
            },
            "claude-3-haiku": {
                "provider": "anthropic",
                "cost_per_1k_tokens": 0.00025,
                "max_tokens": 200000,
                "speed": "fast",
                "quality": "very_good",
                "use_case": "Balanceado - boa qualidade, bom pre√ßo"
            },
            "claude-3-5-sonnet": {
                "provider": "anthropic",
                "cost_per_1k_tokens": 0.003,
                "max_tokens": 200000,
                "speed": "medium",
                "quality": "excellent",
                "use_case": "Textos longos, an√°lises profundas"
            },
            "gemini-1.5-pro": {
                "provider": "google",
                "cost_per_1k_tokens": 0.00125,
                "max_tokens": 1000000,
                "speed": "medium",
                "quality": "excellent",
                "use_case": "Criatividade, contexto gigante"
            }
        }

        # üéØ Regras de roteamento (para refer√™ncia)
        self.routing_rules = {
            "code_detection": ["c√≥digo", "code", "python", "javascript", "debug"],
            "simple_questions": ["o que √©", "como", "quando", "onde"],
            "creative_content": ["criativo", "marketing", "hist√≥ria", "poema"],
            "long_text_threshold": 1000,
            "simple_text_threshold": 100
        }

        # üîß Configura√ß√µes gerais (din√¢micas baseadas nas APIs dispon√≠veis)
        self.default_model = self._get_default_model()
        self.fallback_model = self._get_fallback_model()
        self.max_retries = 3
        self.timeout_seconds = 30
    
    def _detect_available_providers(self) -> List[str]:
        """Detecta quais provedores est√£o dispon√≠veis baseado nas chaves de API"""
        providers = []
        
        # Verifica OpenAI
        if os.getenv('OPENAI_API_KEY'):
            providers.append('openai')
        
        # Verifica Anthropic
        if os.getenv('ANTHROPIC_API_KEY'):
            providers.append('anthropic')
        
        # Verifica Google
        if os.getenv('GOOGLE_API_KEY'):
            providers.append('google')
        
        return providers
    
    def _get_default_model(self) -> str:
        """Retorna o modelo padr√£o baseado nas APIs dispon√≠veis"""
        # Prioridade: Anthropic > OpenAI > Google
        if 'anthropic' in self.available_providers:
            return 'claude-3-haiku'
        elif 'openai' in self.available_providers:
            return 'gpt-4o-mini'
        elif 'google' in self.available_providers:
            return 'gemini-1.5-pro'
        else:
            # Se nenhuma API dispon√≠vel, retorna o primeiro modelo (ser√° tratado como erro)
            return 'gpt-4o-mini'
    
    def _get_fallback_model(self) -> str:
        """Retorna o modelo de fallback baseado nas APIs dispon√≠veis"""
        # Se OpenAI dispon√≠vel, usa como fallback
        if 'openai' in self.available_providers:
            return 'gpt-4o-mini'
        # Sen√£o, usa o mesmo que o padr√£o
        return self.default_model
    
    def get_available_models(self) -> Dict[str, dict]:
        """Retorna apenas os modelos dos provedores dispon√≠veis"""
        available_models = {}
        for model_name, model_config in self.models.items():
            if model_config['provider'] in self.available_providers:
                available_models[model_name] = model_config
        return available_models
    
    def is_provider_available(self, provider: str) -> bool:
        """Verifica se um provedor espec√≠fico est√° dispon√≠vel"""
        return provider in self.available_providers
